{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Reinforcement learning is the process of learning by interacting with an environment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `installing the important libraries and modules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8K8ZMFn14IN",
    "outputId": "49e1b5c0-3fc3-4340-df26-ea840c5b80fc"
   },
   "outputs": [],
   "source": [
    "!pip install cmake 'gym[atari]' scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym[toy_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `my functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showEnvInfo(env):\n",
    "    print(\"Action Space {}\".format(env.action_space))\n",
    "    print(\"State  Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force(env):\n",
    "    epochs = 0\n",
    "    penalties, rewards = 0, 0\n",
    "\n",
    "    frames = [] # for animation\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        if reward > 0:\n",
    "            rewards += 1\n",
    "\n",
    "        # Put each rendered frame into dict for animation\n",
    "        frames.append({\n",
    "            'frame': env.render(mode='ansi'),\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'reward': reward\n",
    "            })\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "\n",
    "    print(\"Timesteps taken: {}\".format(epochs))\n",
    "    print(\"Penalties incurred: {}\".format(penalties))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTheAgent(env,alpha=0.1,gamma=0.6,epsilon=0.1):\n",
    "    \"\"\"Training the agent\"\"\"\n",
    "\n",
    "    # Initialize the q table\n",
    "    q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "    # For plotting metrics\n",
    "    all_epochs = []\n",
    "    all_penalties = []\n",
    "\n",
    "    for i in range(1, 100001):\n",
    "        state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = env.action_space.sample() # Explore action space\n",
    "            else:\n",
    "                action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "            next_state, reward, done, info = env.step(action) \n",
    "\n",
    "            old_value = q_table[state, action]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state, action] = new_value\n",
    "\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Episode: {i}\")\n",
    "\n",
    "    print(\"Training finished.\\n\")\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTheAgent(q_table,episodes = 1000):\n",
    "    \"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
    "    total_epochs, total_penalties = 0, 0\n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()\n",
    "        epochs, penalties, reward = 0, 0, 0\n",
    "\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = np.argmax(q_table[state])\n",
    "            state, reward, done, info = env.step(action)\n",
    "\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "        total_penalties += penalties\n",
    "        total_epochs += epochs\n",
    "\n",
    "    print(f\"Results after {episodes} episodes:\")\n",
    "    print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "    print(f\"Average penalties per episode: {total_penalties / episodes}\")\n",
    "    avr_time = total_epochs / episodes\n",
    "    avr_pen  = total_penalties / episodes\n",
    "    return avr_time , avr_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizedTraining(env,alpha=0.1,gamma=0.6,epsilon=0.1):\n",
    "    \"\"\"Training the agent\"\"\"\n",
    "\n",
    "    # Initialize the q table\n",
    "    q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "    # For plotting metrics\n",
    "    all_epochs = []\n",
    "    all_penalties = []\n",
    "\n",
    "    for i in range(1, 100001):\n",
    "\n",
    "        if i in [10000,25000,40000,55000,70000,85000,90000]:\n",
    "            epsilon = epsilon*0.1\n",
    "#             gamma = gamma-0.005\n",
    "#             alpha = alpha*0.5\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = env.action_space.sample() # Explore action space\n",
    "            else:\n",
    "                action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "            next_state, reward, done, info = env.step(action) \n",
    "\n",
    "            old_value = q_table[state, action]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state, action] = new_value\n",
    "\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Episode: {i}\")\n",
    "\n",
    "    print(\"Training finished.\\n\")\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Gym`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gym is released by Open AI in 2016. It is a toolkit for developing and comparing reinforcement learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([EnvSpec(id='ALE/Tetris-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, kwargs={'game': 'tetris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris', version=5), EnvSpec(id='ALE/Tetris-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, kwargs={'game': 'tetris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris-ram', version=5), EnvSpec(id='Adventure-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=0), EnvSpec(id='AdventureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=0), EnvSpec(id='AdventureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=0), EnvSpec(id='Adventure-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=4), EnvSpec(id='AdventureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=4), EnvSpec(id='AdventureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=4), EnvSpec(id='Adventure-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=0), EnvSpec(id='Adventure-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=0), EnvSpec(id='Adventure-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=0), EnvSpec(id='Adventure-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=4), EnvSpec(id='Adventure-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=4), EnvSpec(id='Adventure-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=4), EnvSpec(id='AirRaid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=0), EnvSpec(id='AirRaidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=0), EnvSpec(id='AirRaidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=0), EnvSpec(id='AirRaid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=4), EnvSpec(id='AirRaidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=4), EnvSpec(id='AirRaidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=4), EnvSpec(id='AirRaid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=0), EnvSpec(id='AirRaid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=0), EnvSpec(id='AirRaid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=0), EnvSpec(id='AirRaid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=4), EnvSpec(id='AirRaid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=4), EnvSpec(id='AirRaid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=4), EnvSpec(id='Alien-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=0), EnvSpec(id='AlienDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=0), EnvSpec(id='AlienNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=0), EnvSpec(id='Alien-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=4), EnvSpec(id='AlienDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=4), EnvSpec(id='AlienNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=4), EnvSpec(id='Alien-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=0), EnvSpec(id='Alien-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=0), EnvSpec(id='Alien-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=0), EnvSpec(id='Alien-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=4), EnvSpec(id='Alien-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=4), EnvSpec(id='Alien-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=4), EnvSpec(id='Amidar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=0), EnvSpec(id='AmidarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=0), EnvSpec(id='AmidarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=0), EnvSpec(id='Amidar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=4), EnvSpec(id='AmidarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=4), EnvSpec(id='AmidarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=4), EnvSpec(id='Amidar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=0), EnvSpec(id='Amidar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=0), EnvSpec(id='Amidar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=0), EnvSpec(id='Amidar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=4), EnvSpec(id='Amidar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=4), EnvSpec(id='Amidar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=4), EnvSpec(id='Assault-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=0), EnvSpec(id='AssaultDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=0), EnvSpec(id='AssaultNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=0), EnvSpec(id='Assault-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=4), EnvSpec(id='AssaultDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=4), EnvSpec(id='AssaultNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=4), EnvSpec(id='Assault-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=0), EnvSpec(id='Assault-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=0), EnvSpec(id='Assault-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=0), EnvSpec(id='Assault-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=4), EnvSpec(id='Assault-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=4), EnvSpec(id='Assault-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=4), EnvSpec(id='Asterix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=0), EnvSpec(id='AsterixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=0), EnvSpec(id='AsterixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=0), EnvSpec(id='Asterix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=4), EnvSpec(id='AsterixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=4), EnvSpec(id='AsterixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=4), EnvSpec(id='Asterix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=0), EnvSpec(id='Asterix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=0), EnvSpec(id='Asterix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=0), EnvSpec(id='Asterix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=4), EnvSpec(id='Asterix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=4), EnvSpec(id='Asterix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=4), EnvSpec(id='Asteroids-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=0), EnvSpec(id='AsteroidsDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=0), EnvSpec(id='AsteroidsNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=0), EnvSpec(id='Asteroids-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=4), EnvSpec(id='AsteroidsDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=4), EnvSpec(id='AsteroidsNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=4), EnvSpec(id='Asteroids-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=0), EnvSpec(id='Asteroids-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=0), EnvSpec(id='Asteroids-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=0), EnvSpec(id='Asteroids-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=4), EnvSpec(id='Asteroids-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=4), EnvSpec(id='Asteroids-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=4), EnvSpec(id='Atlantis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=0), EnvSpec(id='AtlantisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=0), EnvSpec(id='AtlantisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=0), EnvSpec(id='Atlantis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=4), EnvSpec(id='AtlantisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=4), EnvSpec(id='AtlantisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=4), EnvSpec(id='Atlantis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=0), EnvSpec(id='Atlantis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=0), EnvSpec(id='Atlantis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=0), EnvSpec(id='Atlantis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=4), EnvSpec(id='Atlantis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=4), EnvSpec(id='Atlantis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=4), EnvSpec(id='BankHeist-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=0), EnvSpec(id='BankHeistDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=0), EnvSpec(id='BankHeistNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=0), EnvSpec(id='BankHeist-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=4), EnvSpec(id='BankHeistDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=4), EnvSpec(id='BankHeistNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=4), EnvSpec(id='BankHeist-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=0), EnvSpec(id='BankHeist-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=0), EnvSpec(id='BankHeist-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=0), EnvSpec(id='BankHeist-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=4), EnvSpec(id='BankHeist-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=4), EnvSpec(id='BankHeist-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=4), EnvSpec(id='BattleZone-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=0), EnvSpec(id='BattleZoneDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=0), EnvSpec(id='BattleZoneNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=0), EnvSpec(id='BattleZone-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=4), EnvSpec(id='BattleZoneDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=4), EnvSpec(id='BattleZoneNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=4), EnvSpec(id='BattleZone-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=0), EnvSpec(id='BattleZone-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=0), EnvSpec(id='BattleZone-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=0), EnvSpec(id='BattleZone-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=4), EnvSpec(id='BattleZone-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=4), EnvSpec(id='BattleZone-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=4), EnvSpec(id='BeamRider-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=0), EnvSpec(id='BeamRiderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=0), EnvSpec(id='BeamRiderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=0), EnvSpec(id='BeamRider-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=4), EnvSpec(id='BeamRiderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=4), EnvSpec(id='BeamRiderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=4), EnvSpec(id='BeamRider-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=0), EnvSpec(id='BeamRider-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=0), EnvSpec(id='BeamRider-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=0), EnvSpec(id='BeamRider-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=4), EnvSpec(id='BeamRider-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=4), EnvSpec(id='BeamRider-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=4), EnvSpec(id='Berzerk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=0), EnvSpec(id='BerzerkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=0), EnvSpec(id='BerzerkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=0), EnvSpec(id='Berzerk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=4), EnvSpec(id='BerzerkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=4), EnvSpec(id='BerzerkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=4), EnvSpec(id='Berzerk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=0), EnvSpec(id='Berzerk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=0), EnvSpec(id='Berzerk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=0), EnvSpec(id='Berzerk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=4), EnvSpec(id='Berzerk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=4), EnvSpec(id='Berzerk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=4), EnvSpec(id='Bowling-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=0), EnvSpec(id='BowlingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=0), EnvSpec(id='BowlingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=0), EnvSpec(id='Bowling-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=4), EnvSpec(id='BowlingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=4), EnvSpec(id='BowlingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=4), EnvSpec(id='Bowling-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=0), EnvSpec(id='Bowling-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=0), EnvSpec(id='Bowling-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=0), EnvSpec(id='Bowling-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=4), EnvSpec(id='Bowling-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=4), EnvSpec(id='Bowling-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=4), EnvSpec(id='Boxing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=0), EnvSpec(id='BoxingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=0), EnvSpec(id='BoxingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=0), EnvSpec(id='Boxing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=4), EnvSpec(id='BoxingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=4), EnvSpec(id='BoxingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=4), EnvSpec(id='Boxing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=0), EnvSpec(id='Boxing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=0), EnvSpec(id='Boxing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=0), EnvSpec(id='Boxing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=4), EnvSpec(id='Boxing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=4), EnvSpec(id='Boxing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=4), EnvSpec(id='Breakout-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=0), EnvSpec(id='BreakoutDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=0), EnvSpec(id='BreakoutNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=0), EnvSpec(id='Breakout-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=4), EnvSpec(id='BreakoutDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=4), EnvSpec(id='BreakoutNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=4), EnvSpec(id='Breakout-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=0), EnvSpec(id='Breakout-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=0), EnvSpec(id='Breakout-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=0), EnvSpec(id='Breakout-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=4), EnvSpec(id='Breakout-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=4), EnvSpec(id='Breakout-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=4), EnvSpec(id='Carnival-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=0), EnvSpec(id='CarnivalDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=0), EnvSpec(id='CarnivalNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=0), EnvSpec(id='Carnival-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=4), EnvSpec(id='CarnivalDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=4), EnvSpec(id='CarnivalNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=4), EnvSpec(id='Carnival-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=0), EnvSpec(id='Carnival-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=0), EnvSpec(id='Carnival-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=0), EnvSpec(id='Carnival-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=4), EnvSpec(id='Carnival-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=4), EnvSpec(id='Carnival-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=4), EnvSpec(id='Centipede-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=0), EnvSpec(id='CentipedeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=0), EnvSpec(id='CentipedeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=0), EnvSpec(id='Centipede-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=4), EnvSpec(id='CentipedeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=4), EnvSpec(id='CentipedeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=4), EnvSpec(id='Centipede-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=0), EnvSpec(id='Centipede-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=0), EnvSpec(id='Centipede-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=0), EnvSpec(id='Centipede-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=4), EnvSpec(id='Centipede-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=4), EnvSpec(id='Centipede-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=4), EnvSpec(id='ChopperCommand-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=0), EnvSpec(id='ChopperCommandDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=0), EnvSpec(id='ChopperCommandNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=0), EnvSpec(id='ChopperCommand-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=4), EnvSpec(id='ChopperCommandDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=4), EnvSpec(id='ChopperCommandNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=4), EnvSpec(id='ChopperCommand-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=0), EnvSpec(id='ChopperCommand-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=0), EnvSpec(id='ChopperCommand-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=0), EnvSpec(id='ChopperCommand-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=4), EnvSpec(id='ChopperCommand-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=4), EnvSpec(id='ChopperCommand-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=4), EnvSpec(id='CrazyClimber-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=0), EnvSpec(id='CrazyClimberDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=0), EnvSpec(id='CrazyClimberNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=0), EnvSpec(id='CrazyClimber-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=4), EnvSpec(id='CrazyClimberDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=4), EnvSpec(id='CrazyClimberNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=4), EnvSpec(id='CrazyClimber-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=0), EnvSpec(id='CrazyClimber-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=0), EnvSpec(id='CrazyClimber-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=0), EnvSpec(id='CrazyClimber-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=4), EnvSpec(id='CrazyClimber-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=4), EnvSpec(id='CrazyClimber-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=4), EnvSpec(id='Defender-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=0), EnvSpec(id='DefenderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=0), EnvSpec(id='DefenderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=0), EnvSpec(id='Defender-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=4), EnvSpec(id='DefenderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=4), EnvSpec(id='DefenderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=4), EnvSpec(id='Defender-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=0), EnvSpec(id='Defender-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=0), EnvSpec(id='Defender-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=0), EnvSpec(id='Defender-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=4), EnvSpec(id='Defender-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=4), EnvSpec(id='Defender-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=4), EnvSpec(id='DemonAttack-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=0), EnvSpec(id='DemonAttackDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=0), EnvSpec(id='DemonAttackNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=0), EnvSpec(id='DemonAttack-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=4), EnvSpec(id='DemonAttackDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=4), EnvSpec(id='DemonAttackNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=4), EnvSpec(id='DemonAttack-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=0), EnvSpec(id='DemonAttack-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=0), EnvSpec(id='DemonAttack-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=0), EnvSpec(id='DemonAttack-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=4), EnvSpec(id='DemonAttack-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=4), EnvSpec(id='DemonAttack-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=4), EnvSpec(id='DoubleDunk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=0), EnvSpec(id='DoubleDunkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=0), EnvSpec(id='DoubleDunkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=0), EnvSpec(id='DoubleDunk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=4), EnvSpec(id='DoubleDunkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=4), EnvSpec(id='DoubleDunkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=4), EnvSpec(id='DoubleDunk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=0), EnvSpec(id='DoubleDunk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=0), EnvSpec(id='DoubleDunk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=0), EnvSpec(id='DoubleDunk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=4), EnvSpec(id='DoubleDunk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=4), EnvSpec(id='DoubleDunk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=4), EnvSpec(id='ElevatorAction-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=0), EnvSpec(id='ElevatorActionDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=0), EnvSpec(id='ElevatorActionNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=0), EnvSpec(id='ElevatorAction-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=4), EnvSpec(id='ElevatorActionDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=4), EnvSpec(id='ElevatorActionNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=4), EnvSpec(id='ElevatorAction-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=0), EnvSpec(id='ElevatorAction-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=0), EnvSpec(id='ElevatorAction-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=0), EnvSpec(id='ElevatorAction-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=4), EnvSpec(id='ElevatorAction-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=4), EnvSpec(id='ElevatorAction-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=4), EnvSpec(id='Enduro-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=0), EnvSpec(id='EnduroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=0), EnvSpec(id='EnduroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=0), EnvSpec(id='Enduro-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=4), EnvSpec(id='EnduroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=4), EnvSpec(id='EnduroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=4), EnvSpec(id='Enduro-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=0), EnvSpec(id='Enduro-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=0), EnvSpec(id='Enduro-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=0), EnvSpec(id='Enduro-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=4), EnvSpec(id='Enduro-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=4), EnvSpec(id='Enduro-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=4), EnvSpec(id='FishingDerby-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=0), EnvSpec(id='FishingDerbyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=0), EnvSpec(id='FishingDerbyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=0), EnvSpec(id='FishingDerby-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=4), EnvSpec(id='FishingDerbyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=4), EnvSpec(id='FishingDerbyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=4), EnvSpec(id='FishingDerby-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=0), EnvSpec(id='FishingDerby-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=0), EnvSpec(id='FishingDerby-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=0), EnvSpec(id='FishingDerby-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=4), EnvSpec(id='FishingDerby-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=4), EnvSpec(id='FishingDerby-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=4), EnvSpec(id='Freeway-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=0), EnvSpec(id='FreewayDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=0), EnvSpec(id='FreewayNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=0), EnvSpec(id='Freeway-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=4), EnvSpec(id='FreewayDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=4), EnvSpec(id='FreewayNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=4), EnvSpec(id='Freeway-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=0), EnvSpec(id='Freeway-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=0), EnvSpec(id='Freeway-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=0), EnvSpec(id='Freeway-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=4), EnvSpec(id='Freeway-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=4), EnvSpec(id='Freeway-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=4), EnvSpec(id='Frostbite-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=0), EnvSpec(id='FrostbiteDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=0), EnvSpec(id='FrostbiteNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=0), EnvSpec(id='Frostbite-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=4), EnvSpec(id='FrostbiteDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=4), EnvSpec(id='FrostbiteNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=4), EnvSpec(id='Frostbite-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=0), EnvSpec(id='Frostbite-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=0), EnvSpec(id='Frostbite-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=0), EnvSpec(id='Frostbite-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=4), EnvSpec(id='Frostbite-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=4), EnvSpec(id='Frostbite-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=4), EnvSpec(id='Gopher-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=0), EnvSpec(id='GopherDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=0), EnvSpec(id='GopherNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=0), EnvSpec(id='Gopher-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=4), EnvSpec(id='GopherDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=4), EnvSpec(id='GopherNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=4), EnvSpec(id='Gopher-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=0), EnvSpec(id='Gopher-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=0), EnvSpec(id='Gopher-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=0), EnvSpec(id='Gopher-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=4), EnvSpec(id='Gopher-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=4), EnvSpec(id='Gopher-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=4), EnvSpec(id='Gravitar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=0), EnvSpec(id='GravitarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=0), EnvSpec(id='GravitarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=0), EnvSpec(id='Gravitar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=4), EnvSpec(id='GravitarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=4), EnvSpec(id='GravitarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=4), EnvSpec(id='Gravitar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=0), EnvSpec(id='Gravitar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=0), EnvSpec(id='Gravitar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=0), EnvSpec(id='Gravitar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=4), EnvSpec(id='Gravitar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=4), EnvSpec(id='Gravitar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=4), EnvSpec(id='Hero-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=0), EnvSpec(id='HeroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=0), EnvSpec(id='HeroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=0), EnvSpec(id='Hero-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=4), EnvSpec(id='HeroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=4), EnvSpec(id='HeroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=4), EnvSpec(id='Hero-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=0), EnvSpec(id='Hero-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=0), EnvSpec(id='Hero-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=0), EnvSpec(id='Hero-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=4), EnvSpec(id='Hero-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=4), EnvSpec(id='Hero-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=4), EnvSpec(id='IceHockey-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=0), EnvSpec(id='IceHockeyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=0), EnvSpec(id='IceHockeyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=0), EnvSpec(id='IceHockey-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=4), EnvSpec(id='IceHockeyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=4), EnvSpec(id='IceHockeyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=4), EnvSpec(id='IceHockey-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=0), EnvSpec(id='IceHockey-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=0), EnvSpec(id='IceHockey-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=0), EnvSpec(id='IceHockey-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=4), EnvSpec(id='IceHockey-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=4), EnvSpec(id='IceHockey-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=4), EnvSpec(id='Jamesbond-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=0), EnvSpec(id='JamesbondDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=0), EnvSpec(id='JamesbondNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=0), EnvSpec(id='Jamesbond-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=4), EnvSpec(id='JamesbondDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=4), EnvSpec(id='JamesbondNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=4), EnvSpec(id='Jamesbond-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=0), EnvSpec(id='Jamesbond-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=0), EnvSpec(id='Jamesbond-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=0), EnvSpec(id='Jamesbond-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=4), EnvSpec(id='Jamesbond-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=4), EnvSpec(id='Jamesbond-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=4), EnvSpec(id='JourneyEscape-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=0), EnvSpec(id='JourneyEscapeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=0), EnvSpec(id='JourneyEscapeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=0), EnvSpec(id='JourneyEscape-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=4), EnvSpec(id='JourneyEscapeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=4), EnvSpec(id='JourneyEscapeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=4), EnvSpec(id='JourneyEscape-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=0), EnvSpec(id='JourneyEscape-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=0), EnvSpec(id='JourneyEscape-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=0), EnvSpec(id='JourneyEscape-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=4), EnvSpec(id='JourneyEscape-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=4), EnvSpec(id='JourneyEscape-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=4), EnvSpec(id='Kangaroo-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=0), EnvSpec(id='KangarooDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=0), EnvSpec(id='KangarooNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=0), EnvSpec(id='Kangaroo-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=4), EnvSpec(id='KangarooDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=4), EnvSpec(id='KangarooNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=4), EnvSpec(id='Kangaroo-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=0), EnvSpec(id='Kangaroo-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=0), EnvSpec(id='Kangaroo-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=0), EnvSpec(id='Kangaroo-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=4), EnvSpec(id='Kangaroo-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=4), EnvSpec(id='Kangaroo-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=4), EnvSpec(id='Krull-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=0), EnvSpec(id='KrullDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=0), EnvSpec(id='KrullNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=0), EnvSpec(id='Krull-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=4), EnvSpec(id='KrullDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=4), EnvSpec(id='KrullNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=4), EnvSpec(id='Krull-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=0), EnvSpec(id='Krull-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=0), EnvSpec(id='Krull-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=0), EnvSpec(id='Krull-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=4), EnvSpec(id='Krull-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=4), EnvSpec(id='Krull-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=4), EnvSpec(id='KungFuMaster-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=0), EnvSpec(id='KungFuMasterDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=0), EnvSpec(id='KungFuMasterNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=0), EnvSpec(id='KungFuMaster-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=4), EnvSpec(id='KungFuMasterDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=4), EnvSpec(id='KungFuMasterNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=4), EnvSpec(id='KungFuMaster-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=0), EnvSpec(id='KungFuMaster-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=0), EnvSpec(id='KungFuMaster-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=0), EnvSpec(id='KungFuMaster-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=4), EnvSpec(id='KungFuMaster-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=4), EnvSpec(id='KungFuMaster-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=4), EnvSpec(id='MontezumaRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=0), EnvSpec(id='MontezumaRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=0), EnvSpec(id='MontezumaRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=0), EnvSpec(id='MontezumaRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=4), EnvSpec(id='MontezumaRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=4), EnvSpec(id='MontezumaRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=4), EnvSpec(id='MontezumaRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=0), EnvSpec(id='MontezumaRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=0), EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=0), EnvSpec(id='MontezumaRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=4), EnvSpec(id='MontezumaRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=4), EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=4), EnvSpec(id='MsPacman-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=0), EnvSpec(id='MsPacmanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=0), EnvSpec(id='MsPacmanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=0), EnvSpec(id='MsPacman-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=4), EnvSpec(id='MsPacmanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=4), EnvSpec(id='MsPacmanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=4), EnvSpec(id='MsPacman-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=0), EnvSpec(id='MsPacman-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=0), EnvSpec(id='MsPacman-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=0), EnvSpec(id='MsPacman-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=4), EnvSpec(id='MsPacman-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=4), EnvSpec(id='MsPacman-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=4), EnvSpec(id='NameThisGame-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=0), EnvSpec(id='NameThisGameDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=0), EnvSpec(id='NameThisGameNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=0), EnvSpec(id='NameThisGame-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=4), EnvSpec(id='NameThisGameDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=4), EnvSpec(id='NameThisGameNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=4), EnvSpec(id='NameThisGame-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=0), EnvSpec(id='NameThisGame-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=0), EnvSpec(id='NameThisGame-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=0), EnvSpec(id='NameThisGame-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=4), EnvSpec(id='NameThisGame-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=4), EnvSpec(id='NameThisGame-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=4), EnvSpec(id='Phoenix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=0), EnvSpec(id='PhoenixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=0), EnvSpec(id='PhoenixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=0), EnvSpec(id='Phoenix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=4), EnvSpec(id='PhoenixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=4), EnvSpec(id='PhoenixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=4), EnvSpec(id='Phoenix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=0), EnvSpec(id='Phoenix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=0), EnvSpec(id='Phoenix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=0), EnvSpec(id='Phoenix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=4), EnvSpec(id='Phoenix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=4), EnvSpec(id='Phoenix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=4), EnvSpec(id='Pitfall-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=0), EnvSpec(id='PitfallDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=0), EnvSpec(id='PitfallNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=0), EnvSpec(id='Pitfall-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=4), EnvSpec(id='PitfallDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=4), EnvSpec(id='PitfallNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=4), EnvSpec(id='Pitfall-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=0), EnvSpec(id='Pitfall-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=0), EnvSpec(id='Pitfall-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=0), EnvSpec(id='Pitfall-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=4), EnvSpec(id='Pitfall-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=4), EnvSpec(id='Pitfall-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=4), EnvSpec(id='Pong-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=0), EnvSpec(id='PongDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=0), EnvSpec(id='PongNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=0), EnvSpec(id='Pong-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=4), EnvSpec(id='PongDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4), EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=4), EnvSpec(id='Pong-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=0), EnvSpec(id='Pong-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=0), EnvSpec(id='Pong-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=0), EnvSpec(id='Pong-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=4), EnvSpec(id='Pong-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=4), EnvSpec(id='Pong-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=4), EnvSpec(id='Pooyan-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=0), EnvSpec(id='PooyanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=0), EnvSpec(id='PooyanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=0), EnvSpec(id='Pooyan-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=4), EnvSpec(id='PooyanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=4), EnvSpec(id='PooyanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=4), EnvSpec(id='Pooyan-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=0), EnvSpec(id='Pooyan-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=0), EnvSpec(id='Pooyan-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=0), EnvSpec(id='Pooyan-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=4), EnvSpec(id='Pooyan-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=4), EnvSpec(id='Pooyan-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=4), EnvSpec(id='PrivateEye-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=0), EnvSpec(id='PrivateEyeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=0), EnvSpec(id='PrivateEyeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=0), EnvSpec(id='PrivateEye-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=4), EnvSpec(id='PrivateEyeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=4), EnvSpec(id='PrivateEyeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=4), EnvSpec(id='PrivateEye-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=0), EnvSpec(id='PrivateEye-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=0), EnvSpec(id='PrivateEye-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=0), EnvSpec(id='PrivateEye-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=4), EnvSpec(id='PrivateEye-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=4), EnvSpec(id='PrivateEye-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=4), EnvSpec(id='Qbert-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=0), EnvSpec(id='QbertDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=0), EnvSpec(id='QbertNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=0), EnvSpec(id='Qbert-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=4), EnvSpec(id='QbertDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=4), EnvSpec(id='QbertNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=4), EnvSpec(id='Qbert-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=0), EnvSpec(id='Qbert-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=0), EnvSpec(id='Qbert-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=0), EnvSpec(id='Qbert-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=4), EnvSpec(id='Qbert-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=4), EnvSpec(id='Qbert-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=4), EnvSpec(id='Riverraid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=0), EnvSpec(id='RiverraidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=0), EnvSpec(id='RiverraidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=0), EnvSpec(id='Riverraid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=4), EnvSpec(id='RiverraidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=4), EnvSpec(id='RiverraidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=4), EnvSpec(id='Riverraid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=0), EnvSpec(id='Riverraid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=0), EnvSpec(id='Riverraid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=0), EnvSpec(id='Riverraid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=4), EnvSpec(id='Riverraid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=4), EnvSpec(id='Riverraid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=4), EnvSpec(id='RoadRunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=0), EnvSpec(id='RoadRunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=0), EnvSpec(id='RoadRunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=0), EnvSpec(id='RoadRunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=4), EnvSpec(id='RoadRunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=4), EnvSpec(id='RoadRunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=4), EnvSpec(id='RoadRunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=0), EnvSpec(id='RoadRunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=0), EnvSpec(id='RoadRunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=0), EnvSpec(id='RoadRunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=4), EnvSpec(id='RoadRunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=4), EnvSpec(id='RoadRunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=4), EnvSpec(id='Robotank-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=0), EnvSpec(id='RobotankDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=0), EnvSpec(id='RobotankNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=0), EnvSpec(id='Robotank-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=4), EnvSpec(id='RobotankDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=4), EnvSpec(id='RobotankNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=4), EnvSpec(id='Robotank-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=0), EnvSpec(id='Robotank-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=0), EnvSpec(id='Robotank-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=0), EnvSpec(id='Robotank-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=4), EnvSpec(id='Robotank-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=4), EnvSpec(id='Robotank-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=4), EnvSpec(id='Seaquest-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=0), EnvSpec(id='SeaquestDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=0), EnvSpec(id='SeaquestNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=0), EnvSpec(id='Seaquest-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=4), EnvSpec(id='SeaquestDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=4), EnvSpec(id='SeaquestNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=4), EnvSpec(id='Seaquest-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=0), EnvSpec(id='Seaquest-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=0), EnvSpec(id='Seaquest-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=0), EnvSpec(id='Seaquest-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=4), EnvSpec(id='Seaquest-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=4), EnvSpec(id='Seaquest-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=4), EnvSpec(id='Skiing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=0), EnvSpec(id='SkiingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=0), EnvSpec(id='SkiingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=0), EnvSpec(id='Skiing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=4), EnvSpec(id='SkiingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=4), EnvSpec(id='SkiingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=4), EnvSpec(id='Skiing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=0), EnvSpec(id='Skiing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=0), EnvSpec(id='Skiing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=0), EnvSpec(id='Skiing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=4), EnvSpec(id='Skiing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=4), EnvSpec(id='Skiing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=4), EnvSpec(id='Solaris-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=0), EnvSpec(id='SolarisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=0), EnvSpec(id='SolarisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=0), EnvSpec(id='Solaris-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=4), EnvSpec(id='SolarisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=4), EnvSpec(id='SolarisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=4), EnvSpec(id='Solaris-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=0), EnvSpec(id='Solaris-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=0), EnvSpec(id='Solaris-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=0), EnvSpec(id='Solaris-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=4), EnvSpec(id='Solaris-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=4), EnvSpec(id='Solaris-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=4), EnvSpec(id='SpaceInvaders-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=0), EnvSpec(id='SpaceInvadersDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=0), EnvSpec(id='SpaceInvadersNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=0), EnvSpec(id='SpaceInvaders-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=4), EnvSpec(id='SpaceInvadersDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=4), EnvSpec(id='SpaceInvadersNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=4), EnvSpec(id='SpaceInvaders-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=0), EnvSpec(id='SpaceInvaders-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=0), EnvSpec(id='SpaceInvaders-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=0), EnvSpec(id='SpaceInvaders-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=4), EnvSpec(id='SpaceInvaders-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=4), EnvSpec(id='SpaceInvaders-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=4), EnvSpec(id='StarGunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=0), EnvSpec(id='StarGunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=0), EnvSpec(id='StarGunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=0), EnvSpec(id='StarGunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=4), EnvSpec(id='StarGunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=4), EnvSpec(id='StarGunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=4), EnvSpec(id='StarGunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=0), EnvSpec(id='StarGunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=0), EnvSpec(id='StarGunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=0), EnvSpec(id='StarGunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=4), EnvSpec(id='StarGunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=4), EnvSpec(id='StarGunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=4), EnvSpec(id='Tennis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=0), EnvSpec(id='TennisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=0), EnvSpec(id='TennisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=0), EnvSpec(id='Tennis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=4), EnvSpec(id='TennisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=4), EnvSpec(id='TennisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=4), EnvSpec(id='Tennis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=0), EnvSpec(id='Tennis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=0), EnvSpec(id='Tennis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=0), EnvSpec(id='Tennis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=4), EnvSpec(id='Tennis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=4), EnvSpec(id='Tennis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=4), EnvSpec(id='TimePilot-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=0), EnvSpec(id='TimePilotDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=0), EnvSpec(id='TimePilotNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=0), EnvSpec(id='TimePilot-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=4), EnvSpec(id='TimePilotDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=4), EnvSpec(id='TimePilotNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=4), EnvSpec(id='TimePilot-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=0), EnvSpec(id='TimePilot-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=0), EnvSpec(id='TimePilot-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=0), EnvSpec(id='TimePilot-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=4), EnvSpec(id='TimePilot-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=4), EnvSpec(id='TimePilot-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=4), EnvSpec(id='Tutankham-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=0), EnvSpec(id='TutankhamDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=0), EnvSpec(id='TutankhamNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=0), EnvSpec(id='Tutankham-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=4), EnvSpec(id='TutankhamDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=4), EnvSpec(id='TutankhamNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=4), EnvSpec(id='Tutankham-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=0), EnvSpec(id='Tutankham-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=0), EnvSpec(id='Tutankham-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=0), EnvSpec(id='Tutankham-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=4), EnvSpec(id='Tutankham-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=4), EnvSpec(id='Tutankham-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=4), EnvSpec(id='UpNDown-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=0), EnvSpec(id='UpNDownDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=0), EnvSpec(id='UpNDownNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=0), EnvSpec(id='UpNDown-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=4), EnvSpec(id='UpNDownDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=4), EnvSpec(id='UpNDownNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=4), EnvSpec(id='UpNDown-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=0), EnvSpec(id='UpNDown-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=0), EnvSpec(id='UpNDown-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=0), EnvSpec(id='UpNDown-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=4), EnvSpec(id='UpNDown-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=4), EnvSpec(id='UpNDown-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=4), EnvSpec(id='Venture-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=0), EnvSpec(id='VentureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=0), EnvSpec(id='VentureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=0), EnvSpec(id='Venture-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=4), EnvSpec(id='VentureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=4), EnvSpec(id='VentureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=4), EnvSpec(id='Venture-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=0), EnvSpec(id='Venture-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=0), EnvSpec(id='Venture-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=0), EnvSpec(id='Venture-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=4), EnvSpec(id='Venture-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=4), EnvSpec(id='Venture-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=4), EnvSpec(id='VideoPinball-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=0), EnvSpec(id='VideoPinballDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=0), EnvSpec(id='VideoPinballNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=0), EnvSpec(id='VideoPinball-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=4), EnvSpec(id='VideoPinballDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=4), EnvSpec(id='VideoPinballNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=4), EnvSpec(id='VideoPinball-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=0), EnvSpec(id='VideoPinball-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=0), EnvSpec(id='VideoPinball-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=0), EnvSpec(id='VideoPinball-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=4), EnvSpec(id='VideoPinball-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=4), EnvSpec(id='VideoPinball-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=4), EnvSpec(id='WizardOfWor-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=0), EnvSpec(id='WizardOfWorDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=0), EnvSpec(id='WizardOfWorNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=0), EnvSpec(id='WizardOfWor-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=4), EnvSpec(id='WizardOfWorDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=4), EnvSpec(id='WizardOfWorNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=4), EnvSpec(id='WizardOfWor-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=0), EnvSpec(id='WizardOfWor-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=0), EnvSpec(id='WizardOfWor-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=0), EnvSpec(id='WizardOfWor-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=4), EnvSpec(id='WizardOfWor-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=4), EnvSpec(id='WizardOfWor-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=4), EnvSpec(id='YarsRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=0), EnvSpec(id='YarsRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=0), EnvSpec(id='YarsRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=0), EnvSpec(id='YarsRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=4), EnvSpec(id='YarsRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=4), EnvSpec(id='YarsRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=4), EnvSpec(id='YarsRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=0), EnvSpec(id='YarsRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=0), EnvSpec(id='YarsRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=0), EnvSpec(id='YarsRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=4), EnvSpec(id='YarsRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=4), EnvSpec(id='YarsRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=4), EnvSpec(id='Zaxxon-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=0), EnvSpec(id='ZaxxonDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=0), EnvSpec(id='ZaxxonNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=0), EnvSpec(id='Zaxxon-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=4), EnvSpec(id='ZaxxonDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=4), EnvSpec(id='ZaxxonNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=4), EnvSpec(id='Zaxxon-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=0), EnvSpec(id='Zaxxon-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=0), EnvSpec(id='Zaxxon-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=0), EnvSpec(id='Zaxxon-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=4), EnvSpec(id='Zaxxon-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=4), EnvSpec(id='Zaxxon-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=4), EnvSpec(id='CartPole-v0', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='CartPole', version=0), EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='CartPole', version=1), EnvSpec(id='MountainCar-v0', entry_point='gym.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='MountainCar', version=0), EnvSpec(id='MountainCarContinuous-v0', entry_point='gym.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0), EnvSpec(id='Pendulum-v1', entry_point='gym.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Pendulum', version=1), EnvSpec(id='Acrobot-v1', entry_point='gym.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Acrobot', version=1), EnvSpec(id='LunarLander-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='LunarLander', version=2), EnvSpec(id='LunarLanderContinuous-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2), EnvSpec(id='BipedalWalker-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='BipedalWalker', version=3), EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3), EnvSpec(id='CarRacing-v1', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='CarRacing', version=1), EnvSpec(id='CarRacingDomainRandomize-v1', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={'domain_randomize': True}, namespace=None, name='CarRacingDomainRandomize', version=1), EnvSpec(id='CarRacingDiscrete-v1', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={'continuous': False}, namespace=None, name='CarRacingDiscrete', version=1), EnvSpec(id='CarRacingDomainRandomizeDiscrete-v1', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={'domain_randomize': True, 'continuous': False}, namespace=None, name='CarRacingDomainRandomizeDiscrete', version=1), EnvSpec(id='Blackjack-v1', entry_point='gym.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1), EnvSpec(id='FrozenLake-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1), EnvSpec(id='FrozenLake8x8-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1), EnvSpec(id='CliffWalking-v0', entry_point='gym.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='CliffWalking', version=0), EnvSpec(id='Taxi-v3', entry_point='gym.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Taxi', version=3), EnvSpec(id='Reacher-v2', entry_point='gym.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Reacher', version=2), EnvSpec(id='Reacher-v4', entry_point='gym.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Reacher', version=4), EnvSpec(id='Pusher-v2', entry_point='gym.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Pusher', version=2), EnvSpec(id='Pusher-v4', entry_point='gym.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Pusher', version=4), EnvSpec(id='InvertedPendulum-v2', entry_point='gym.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2), EnvSpec(id='InvertedPendulum-v4', entry_point='gym.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4), EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gym.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2), EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gym.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4), EnvSpec(id='HalfCheetah-v2', entry_point='gym.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='HalfCheetah', version=2), EnvSpec(id='HalfCheetah-v3', entry_point='gym.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='HalfCheetah', version=3), EnvSpec(id='HalfCheetah-v4', entry_point='gym.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='HalfCheetah', version=4), EnvSpec(id='Hopper-v2', entry_point='gym.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Hopper', version=2), EnvSpec(id='Hopper-v3', entry_point='gym.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Hopper', version=3), EnvSpec(id='Hopper-v4', entry_point='gym.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Hopper', version=4), EnvSpec(id='Swimmer-v2', entry_point='gym.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Swimmer', version=2), EnvSpec(id='Swimmer-v3', entry_point='gym.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Swimmer', version=3), EnvSpec(id='Swimmer-v4', entry_point='gym.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Swimmer', version=4), EnvSpec(id='Walker2d-v2', entry_point='gym.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Walker2d', version=2), EnvSpec(id='Walker2d-v3', entry_point='gym.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Walker2d', version=3), EnvSpec(id='Walker2d-v4', entry_point='gym.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Walker2d', version=4), EnvSpec(id='Ant-v2', entry_point='gym.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Ant', version=2), EnvSpec(id='Ant-v3', entry_point='gym.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Ant', version=3), EnvSpec(id='Ant-v4', entry_point='gym.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Ant', version=4), EnvSpec(id='Humanoid-v2', entry_point='gym.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Humanoid', version=2), EnvSpec(id='Humanoid-v3', entry_point='gym.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Humanoid', version=3), EnvSpec(id='Humanoid-v4', entry_point='gym.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='Humanoid', version=4), EnvSpec(id='HumanoidStandup-v2', entry_point='gym.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2), EnvSpec(id='HumanoidStandup-v4', entry_point='gym.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amjad/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:424: UserWarning: \u001b[33mWARN: Custom namespace `ALE` is being overridden by namespace `ALE`. If you are developing a plugin you shouldn't specify a namespace in `register` calls. The namespace is specified through the entry point package metadata.\u001b[0m\n",
      "  f\"Custom namespace `{spec.namespace}` is being overridden \"\n"
     ]
    }
   ],
   "source": [
    "import gym # openAi gym\n",
    "from gym import envs\n",
    "\n",
    "# show all the possible game environments in gym \n",
    "print(envs.registry.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `taxi game`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Actions`: There are 6 discrete deterministic actions:\n",
    "    * 0: move south\n",
    "    * 1: move north\n",
    "    * 2: move east \n",
    "    * 3: move west \n",
    "    * 4: pickup passenger\n",
    "    * 5: dropoff passenger\n",
    "`Rewards`: There is a reward of :\n",
    "    * -1  for each action and an additional reward of \n",
    "    * +20 for delievering the passenger. There is a reward of \n",
    "    * -10 for executing actions \"pickup\" and \"dropoff\" illegally.\n",
    "`Rendering`:\n",
    "    * blue: passenger\n",
    "    * magenta: destination\n",
    "    * yellow: empty taxi\n",
    "    * green: full taxi\n",
    "    * other letters: locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `choose the environment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "# env.reset()\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `show the action space and the state space of an environment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space Discrete(6)\n",
      "State  Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "showEnvInfo(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ` check state depending on user parameter `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n",
    "print(\"State:\", state)\n",
    "\n",
    "# env.s = state\n",
    "# env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`the reward table` When the Taxi environment is created, there is an initial Reward table that's also created, called `P`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default reward values assigned to a given state\n",
    "env.P[state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O40te3BtUfSd"
   },
   "source": [
    "### `Brute-force approach`\n",
    "`Solving the environment without Reinforcement Learning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have our P table for default rewards in each state, we can try to have our taxi navigate just using that.\n",
    "\n",
    "We'll create an infinite loop which runs until one passenger reaches one destination (one episode), or in other words, when the received reward is 20. The env.action_space.sample() method automatically selects one random action from set of all possible actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NcyvYhbPIqz",
    "outputId": "ce8c3113-a330-485d-8e02-fa9e94e81915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 200\n",
      "Penalties incurred: 69\n"
     ]
    }
   ],
   "source": [
    "env.s = 328  # set environment to illustration's state\n",
    "frames=brute_force(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | :\u001b[42m_\u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "Timestep: 200\n",
      "State: 177\n",
      "Action: 5\n",
      "Reward: -10\n"
     ]
    }
   ],
   "source": [
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`the evaluation of Brute-force approach :`\n",
    "\n",
    "+ Not good. Our agent takes thousands of timesteps and makes lots of wrong drop offs to deliver just one passengerto the right destination.\n",
    "\n",
    "+ This is because we aren't learning from past experience. We can run this over and over, and it will never optimize. The agent has no memory of which action was best for each state, which is exactly what Reinforcement Learning will do for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The core of the idea is the Q-matrix Q(s, a). \n",
    "    + It contains the maximum discounted future reward when we perform action a in state s. Or in other words Q(s, a) gives estimates the best course of action a in state s.\n",
    "    \n",
    "+ Q-learning lets the agent use the environment's rewards to learn, over time, the best action to take in a given state.\n",
    "\n",
    "+ we have the reward table, P, that the agent will learn from. It does thing by looking receiving a reward for taking an action in the current state, then updating a Q-value to remember if that action was beneficial.\n",
    "\n",
    "+ The values store in the Q-table are called a Q-values, and they map to a (state, action) combination.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIR_WnoWUtI8"
   },
   "source": [
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spjZSoYqibrT",
    "outputId": "013e62ad-67a4-4c56-a00b-0040a9c0e97e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "q_table=trainTheAgent(env,alpha,gamma,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YPOL15lAEsGR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TaxiEnv.encode of <gym.envs.toy_text.taxi.TaxiEnv object at 0x7f1a9be8b750>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.418371</td>\n",
       "      <td>-2.363951</td>\n",
       "      <td>-2.418371</td>\n",
       "      <td>-2.363951</td>\n",
       "      <td>-2.273252</td>\n",
       "      <td>-11.363950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.870144</td>\n",
       "      <td>-1.450240</td>\n",
       "      <td>-1.870144</td>\n",
       "      <td>-1.450240</td>\n",
       "      <td>-0.750400</td>\n",
       "      <td>-10.450238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.363951</td>\n",
       "      <td>-2.273252</td>\n",
       "      <td>-2.363951</td>\n",
       "      <td>-2.273252</td>\n",
       "      <td>-2.122086</td>\n",
       "      <td>-11.273252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.496192</td>\n",
       "      <td>-2.496650</td>\n",
       "      <td>-2.496192</td>\n",
       "      <td>-2.496861</td>\n",
       "      <td>-9.879304</td>\n",
       "      <td>-9.052992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-2.142047</td>\n",
       "      <td>-2.122065</td>\n",
       "      <td>-2.158180</td>\n",
       "      <td>-2.122064</td>\n",
       "      <td>-6.734701</td>\n",
       "      <td>-5.713853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-1.049266</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>-1.006699</td>\n",
       "      <td>-1.262171</td>\n",
       "      <td>-5.172504</td>\n",
       "      <td>-4.072211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-2.130487</td>\n",
       "      <td>-2.122071</td>\n",
       "      <td>-2.170415</td>\n",
       "      <td>-2.122070</td>\n",
       "      <td>-6.277734</td>\n",
       "      <td>-2.871487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2.519767</td>\n",
       "      <td>1.418401</td>\n",
       "      <td>2.177504</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-2.757710</td>\n",
       "      <td>-2.762881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2          3         4          5\n",
       "0    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000\n",
       "1   -2.418371 -2.363951 -2.418371  -2.363951 -2.273252 -11.363950\n",
       "2   -1.870144 -1.450240 -1.870144  -1.450240 -0.750400 -10.450238\n",
       "3   -2.363951 -2.273252 -2.363951  -2.273252 -2.122086 -11.273252\n",
       "4   -2.496192 -2.496650 -2.496192  -2.496861 -9.879304  -9.052992\n",
       "..        ...       ...       ...        ...       ...        ...\n",
       "495  0.000000  0.000000  0.000000   0.000000  0.000000   0.000000\n",
       "496 -2.142047 -2.122065 -2.158180  -2.122064 -6.734701  -5.713853\n",
       "497 -1.049266  0.416000 -1.006699  -1.262171 -5.172504  -4.072211\n",
       "498 -2.130487 -2.122071 -2.170415  -2.122070 -6.277734  -2.871487\n",
       "499  2.519767  1.418401  2.177504  11.000000 -2.757710  -2.762881\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pandas DataFrame\n",
    "\n",
    "df = pd.DataFrame(q_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.38833015,  -2.27325184,  -2.41198134,  -2.35749418,\n",
       "       -10.68247952, -10.08038733])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[328]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ_rv1Z0U2Yx"
   },
   "source": [
    "# Evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of our agent. \n",
    "+ We don't need to explore actions any further, so now the next action is always selected using the best Q-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXM_lpN_PMj0",
    "outputId": "364738ee-6673-4990-c392-1b6b81900038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 1500 episodes:\n",
      "Average timesteps per episode: 13.125333333333334\n",
      "Average penalties per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 1500\n",
    "avr_time , avr_pen = evaluateTheAgent(q_table,episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Grid-search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "Results after 1000 episodes:\n",
      "Average timesteps per episode: 13.099\n",
      "Average penalties per episode: 0.0\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# alpha   = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# gamma   = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# epsilon = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "alpha   = [0.1,0.2,0.3]\n",
    "gamma   = [0.2,0.4,0.6]\n",
    "epsilon = [0.1,0.2,0.3]\n",
    "episodes = 1000\n",
    "lst = []\n",
    "for a in alpha:\n",
    "    for g in gamma:\n",
    "        for e in epsilon:\n",
    "            # train the model \n",
    "            q_table=trainTheAgent(env,a,g,e)\n",
    "            # evaluate the model \n",
    "            avr_time , avr_pen = evaluateTheAgent(q_table,episodes)\n",
    "            lst.append([a,g,e,avr_time,avr_pen])\n",
    "#             print(f\"alpha : {a} ,gamma :{g} ,epsilon :{e}\")\n",
    "#             print(f\"average time :{avr_time}\")\n",
    "#             print(f\"average penalties:{avr_pen}\")\n",
    "            print(\"==========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>average timestamps</th>\n",
       "      <th>average penelitties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.936</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.044</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.049</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  gamma  epsilon  average timestamps  average penelitties\n",
       "0     0.1    0.2      0.1              13.078                  0.0\n",
       "1     0.1    0.2      0.2              13.247                  0.0\n",
       "2     0.1    0.2      0.3              13.165                  0.0\n",
       "3     0.1    0.4      0.1              13.009                  0.0\n",
       "4     0.1    0.4      0.2              12.936                  0.0\n",
       "5     0.1    0.4      0.3              12.962                  0.0\n",
       "6     0.1    0.6      0.1              13.057                  0.0\n",
       "7     0.1    0.6      0.2              13.121                  0.0\n",
       "8     0.1    0.6      0.3              13.028                  0.0\n",
       "9     0.2    0.2      0.1              12.972                  0.0\n",
       "10    0.2    0.2      0.2              13.009                  0.0\n",
       "11    0.2    0.2      0.3              13.169                  0.0\n",
       "12    0.2    0.4      0.1              13.044                  0.0\n",
       "13    0.2    0.4      0.2              13.049                  0.0\n",
       "14    0.2    0.4      0.3              13.197                  0.0\n",
       "15    0.2    0.6      0.1              13.096                  0.0\n",
       "16    0.2    0.6      0.2              13.130                  0.0\n",
       "17    0.2    0.6      0.3              12.948                  0.0\n",
       "18    0.3    0.2      0.1              12.985                  0.0\n",
       "19    0.3    0.2      0.2              13.008                  0.0\n",
       "20    0.3    0.2      0.3              13.149                  0.0\n",
       "21    0.3    0.4      0.1              13.125                  0.0\n",
       "22    0.3    0.4      0.2              13.029                  0.0\n",
       "23    0.3    0.4      0.3              13.126                  0.0\n",
       "24    0.3    0.6      0.1              13.015                  0.0\n",
       "25    0.3    0.6      0.2              13.201                  0.0\n",
       "26    0.3    0.6      0.3              13.099                  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(lst,columns=['alpha','gamma','epsilon','average timestamps','average penelitties'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `training with decay the epsilon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.428530</td>\n",
       "      <td>-1.428443</td>\n",
       "      <td>-1.428531</td>\n",
       "      <td>-1.428441</td>\n",
       "      <td>-1.428150</td>\n",
       "      <td>-10.402969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.423381</td>\n",
       "      <td>-1.412881</td>\n",
       "      <td>-1.422596</td>\n",
       "      <td>-1.412522</td>\n",
       "      <td>-1.376500</td>\n",
       "      <td>-10.314607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.428418</td>\n",
       "      <td>-1.428066</td>\n",
       "      <td>-1.428416</td>\n",
       "      <td>-1.428082</td>\n",
       "      <td>-1.427166</td>\n",
       "      <td>-9.961342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-8.219044</td>\n",
       "      <td>-9.293971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-1.425589</td>\n",
       "      <td>-1.425868</td>\n",
       "      <td>-1.425928</td>\n",
       "      <td>-1.425624</td>\n",
       "      <td>-6.092563</td>\n",
       "      <td>-6.091202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-1.297153</td>\n",
       "      <td>-1.255058</td>\n",
       "      <td>-1.279848</td>\n",
       "      <td>-1.284897</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-6.923742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-1.426618</td>\n",
       "      <td>-1.426568</td>\n",
       "      <td>-1.426637</td>\n",
       "      <td>-1.426553</td>\n",
       "      <td>-3.655874</td>\n",
       "      <td>-6.057609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.288220</td>\n",
       "      <td>-0.372000</td>\n",
       "      <td>-0.198355</td>\n",
       "      <td>4.999557</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4          5\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000\n",
       "1   -1.428530 -1.428443 -1.428531 -1.428441 -1.428150 -10.402969\n",
       "2   -1.423381 -1.412881 -1.422596 -1.412522 -1.376500 -10.314607\n",
       "3   -1.428418 -1.428066 -1.428416 -1.428082 -1.427166  -9.961342\n",
       "4   -1.428571 -1.428571 -1.428571 -1.428571 -8.219044  -9.293971\n",
       "..        ...       ...       ...       ...       ...        ...\n",
       "495  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000\n",
       "496 -1.425589 -1.425868 -1.425928 -1.425624 -6.092563  -6.091202\n",
       "497 -1.297153 -1.255058 -1.279848 -1.284897 -2.000000  -6.923742\n",
       "498 -1.426618 -1.426568 -1.426637 -1.426553 -3.655874  -6.057609\n",
       "499 -0.288220 -0.372000 -0.198355  4.999557 -2.000000  -2.000000\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.2\n",
    "gamma = 0.3\n",
    "epsilon = 0.1\n",
    "\n",
    "q_table3=optimizedTraining(env,alpha,gamma,epsilon)\n",
    "# Create the pandas DataFrame\n",
    "\n",
    "df3 = pd.DataFrame(q_table3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 1500 episodes:\n",
      "Average timesteps per episode: 13.003333333333334\n",
      "Average penalties per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 1500\n",
    "avr_time , avr_pen = evaluateTheAgent(q_table3,episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `References`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/code/charel/learn-by-example-reinforcement-learning-with-gym\n",
    "2. https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/\n",
    "3. https://youtu.be/-WbN61qtTGQ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
